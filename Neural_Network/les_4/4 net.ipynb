{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в искусственные нейронные сети\n",
    "# Урок 4. TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Содержание методического пособия:\n",
    "\n",
    "\n",
    "<ol>\n",
    "<li>Что такое TensorFlow</li>\n",
    "<li>Основы синтаксиса TensorFlow</li>\n",
    "<li>Пример нейросети на TensorFlow</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Что такое TensorFlow\n",
    "\n",
    "TensorFlow - это фреймворк для создания ML моделей. TensorFlow предназначен в первую очередь для Deep Learning, т.е. создания современных нейросетей. Однако в TensorFlow также есть поддержка некоторых классических ML алгоритмов: K-means clustering, Random Forests, Support Vector Machines, Gaussian Mixture Model clustering, Linear/logistic regression.\n",
    "\n",
    "TensorFlow выпустила компания Google в 2015. TensorFlow - это opensource проект. На данный момент это один из основных инструментов для создания нейросетей в рабочих целях. TensorFlow позволяет создавать нейронные сети как для кластеров из большого количества вычислительных устройств, так и для устройств с относительно небольшой вычислитей мощностью, таких как смартфоны и одноплатные компьютеры.\n",
    "\n",
    "TensorFlow применяется самой компанией Google для ее поиска, почты, переводчика, распознования голоса, внутренних нужд наподобие мониторинга оборудования. TensorFlow используется различными компаниями для различных проектов связанных с компьютерным зрением, решением задач ранжирования и т.д.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основы синтаксиса TensorFlow\n",
    "\n",
    "Процесс создания нейросети на TensorFlow схож с разобранным нами процессом обучения нейросети на Keras. Отличее здесь в том, что здесь нам нужно прописать больше деталей в коде. \n",
    "\n",
    "Название TensorFlow означает поток тензоров. Тензоры - это массивы. Данные в компьютере предствлены часто в виде массивах и работа с этими массивами подразумевает их преобразования. Преобразования осуществляются через, к примеру, математические операции. Работа TensorFlow складывается из цепочки преобразований тензоров, т.е. данных. Сами операции осуществляющие преобразование данных представлены в TensorFlow в виде графов. Особенностью TensorFlow версии 1 является то, что сначала необходимо декларировать переменные и вычисления, которые будут совершенны над ними, а потом уже непосредственно запускать работу над данными. Связано это с тем, что TensorFlow таким образом может сделать предварительные оптимизации для работы. Взглянем на пример создания вычислительного графа и его запуска через запуск сессии:\n",
    "```python\n",
    "    import tensorflow as tf\n",
    "\n",
    "    a = 10\n",
    "    b = 5 \n",
    "    c = tf.add(a, b, name='Sustruct') # декларирование графа\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        print(sess.run(c)) # запуск сессии\n",
    "```\n",
    "\n",
    "Для упрощения протипирования нюансы связанные с созданием сессии опускаются в случае использования TensorFlow в режиме Eager Execution. Также сложности работы с сессиями ликвидированы в TensorFlow 2.0. Однако TensorFlow 2.0 вышла совсем недавно, 1 октября 2019 года, поэтому в данном методическом пособии мы рассматриваем синтаксис TensorFlow 1.x.\n",
    "<br>\n",
    "\n",
    "  Теперь, давайте также как и в прошлом уроке разберем синтаксис TensorFlow позволяющий создать нейросеть, начиная от получения данных и заканчивания получением предсказания нейросети на новых данных.\n",
    "\n",
    "Процесс получения данных для обучения на TensorFlow, а также создания переменных для параметров нейросети аналогичны Keras. \n",
    "<br><br>\n",
    "**Переменные**\n",
    "\n",
    "Для пустых переменных нам понадобиться такая сущность TensorFlow как placeholder. Пример:\n",
    "```python\n",
    "    import tensorflow as tf\n",
    "\n",
    "    x = tf.placeholder(\"float\", None)\n",
    "    y = x * 2\n",
    "```\n",
    "\n",
    "Placeholder'ы можно использовать для резирвирования памяти для входных данных нейросети.\n",
    "<br>\n",
    "Для инициализации переменных, которые будут хранить состояние нейросети нам понадобяться специальная команда TensorFlow - \n",
    "\n",
    "```python\n",
    "    b = tf.Variable([.5],dtype=tf.float32)\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "**Слои**\n",
    "\n",
    "Для создания слоя на TensorFlow нам понадобиться комбинация следующих команд - \n",
    "\n",
    "```python\n",
    "    l1 = tf.add(tf.matmul(x, W['h1']), b['1'])\n",
    "```    \n",
    "    \n",
    "Команды add и matmul позволяют складывать и умножать соотвественно, что позволяет реализовать формулу - Y = X * W(weight) + B(bias)\n",
    "\n",
    "Для активации нейронов выходного слоя можно использовать следующую команду - \n",
    "\n",
    "```python\n",
    "     pred = tf.nn.softmax(data)\n",
    "    \n",
    "```\n",
    "Функция активации softmax, хороша в случаях когда выход нейрона нужно преобразовать либо в 1 либо в 0.\n",
    "<br><br>\n",
    "**Loss функция и Optimizer**\n",
    "\n",
    "Для того, чтобы выбрать loss функцию можно использовать следующую команду\n",
    "```python\n",
    "    loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "                             logits=logits, labels=Y))\n",
    "```                          \n",
    "\n",
    "logits - это значения, которые используются как input для softmax\n",
    "\n",
    "cross entropy function - это функция, которая позволяет сравнить результаты выходного нейрона с лейблами. Например: на выходе нейрона выходного слоя мы должны получить либо 0 либо 1. Но в реальности мы будем получать значения вроде 0.9 или 0.1. Данная функция позволяет превести в соответсвие эти данные.\n",
    "<br>\n",
    "Для того, чтобы выбрать optimizer мы можем воспользоваться следующей функцией -\n",
    "\n",
    "```python\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.3)\n",
    "\n",
    "    train_op = optimizer.minimize(loss_op) \n",
    "```\n",
    "\n",
    "Стоит напомнить, что optimizer позволяет находить минимальное значение функции и является частью нахождения нужных весов в процессе тренировки нейронной сети. Optimizer Adam это продвинутая версия классического алгоритма градиентного спуска. Adam самый быстрый алгоритм для нахождения минимального значения функции поэтому используется обычно он. \n",
    "\n",
    "learning rate позволяет определить размер шага итерации при нахождении минимума\n",
    "minimize - запускает optimizer и принимает в качестве параметра функцию, которую нужно оптимизировать.\n",
    "\n",
    "***Оценка работы модели***\n",
    "\n",
    "Оценку работы нейросети можно осуществить следующей строчкой кода -\n",
    "\n",
    "```python\n",
    "    correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "```\n",
    "\n",
    "argmax - возвращает самое большое значение tensor\n",
    "\n",
    "equal - сравнение векторов, позволяет сравнить предсказание нейросети и правильные ответы\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "reduce_mean позволяет вычислить средние значения в тензоре\n",
    "\n",
    "cast позволяет конверитировать один тип в другой\n",
    "\n",
    "***Запуск обучения нейронной сети***\n",
    "\n",
    "Перед запуском обучение в TensorFlow требуется присвоить значения переменным, которые были задекларированы. Осущевляется это следующей командой - \n",
    "\n",
    "```python\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "```\n",
    "\n",
    "За запуск самой сессии вместе с вышеприведенным инициализатором отвечают следующее строчки кода - \n",
    "\n",
    "```python\n",
    "    with tf.Session() as sess:\n",
    "    \n",
    "        sess.run(init)\n",
    "```\n",
    "        \n",
    "Получение порций данных для каждой итерации обучения, в качетсве аргумента количество экзмепляров данных для обучения -\n",
    "\n",
    "```python\n",
    "     mnist.train.next_batch(10)\n",
    "```\n",
    "     \n",
    "Запуск оптимайзера на данных -  \n",
    "```python\n",
    "     sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "```\n",
    "     \n",
    "Вычисление ошибки в предсказнии и проверка точности - \n",
    "```python\n",
    "     loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
    "                                                                 Y: batch_y}) \n",
    "```    \n",
    "    \n",
    "Тестирование точности нейросети - \n",
    "```python\n",
    "     sess.run(accuracy, feed_dict={X: mnist.test.images,\n",
    "                                      Y: mnist.test.labels}))\n",
    "```\n",
    "\n",
    "Мы рассмотрели основные команды TensorFlow, которые могут понадобиться для обучения нейросети на нем. Полный список команд и возможностей TensorFlow отражает его документация - https://www.tensorflow.org/tutorials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример нейросети на TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте попрубуем сделать нейросеть на Keras использую полученные выше знания. Попробуем обучить нейросеть различать рукописные цифры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.examples'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# получение датасета mnist\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexamples\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtutorials\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmnist\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m input_data\n\u001b[0;32m      5\u001b[0m mnist \u001b[38;5;241m=\u001b[39m input_data\u001b[38;5;241m.\u001b[39mread_data_sets(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/tmp/data/\u001b[39m\u001b[38;5;124m\"\u001b[39m, one_hot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.examples'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# получение датасета mnist\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# параметры обучения нейросети\n",
    "learning_rate = 0.1\n",
    "num_steps = 500\n",
    "batch_size = 128\n",
    "display_step = 100\n",
    "\n",
    "# конфигурация нейросети\n",
    "n_hidden_1 = 256 # кол-во нейронов в первом слое\n",
    "n_hidden_2 = 256 # кол-во нейронов во втором слое\n",
    "num_input = 784 # MNIST датасет (размер изображения: 28*28)\n",
    "num_classes = 10 # MNIST количество классов (0-9 цифр)\n",
    "\n",
    "# входная часть графа\n",
    "X = tf.placeholder(\"float\", [None, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# определение весов и отклонений(bias)\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([num_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "# создание модели\n",
    "def neural_net(x):\n",
    "    # первый внутренний полносвязный слой состоящий из 256 нейронов\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    # второй внутренний полносвязный слой состоящий из 256 нейронов\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    # выход полносвязного слоя с нейроном на каждый класс\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer\n",
    "\n",
    "# конструирование модели\n",
    "logits = neural_net(X)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# выбор loss функции и optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# оценка работы модели\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# инициализация переменных(назначение им значений по умолчанию)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# старт процесса тренировки нейронной сети\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # запуск инициализатора\n",
    "    sess.run(init)\n",
    "    print('')\n",
    "    for step in range(1, num_steps+1):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # запуск оптимизации весов (backpropagation)\n",
    "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # вычисление батч ошибки и точности\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
    "                                                                 Y: batch_y})\n",
    "            print(\"Step \" + str(step) + \", минибатч loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", тренировочная точность = \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "\n",
    "    print(\"Оптимизация завершена\")\n",
    "\n",
    "    # вычисление точности на изображениях датасета MNIST\n",
    "    print(\"Тестовая точность:\", \\\n",
    "        sess.run(accuracy, feed_dict={X: mnist.test.images,\n",
    "                                      Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практическое задание\n",
    "\n",
    "<ol>\n",
    "    <li>Попробуйте обучить нейронную сеть на TensorFlow на любом другом датасете. \n",
    "        Опишите в комментарии к уроку - какой результата вы добились от нейросети? Что помогло вам улучшить ее точность?<br><br>\n",
    "        Примечание: Пользоваться модулем Keras в TensorFlow запрещено в этом практическом задании.\n",
    "    </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дополнительные материалы\n",
    "\n",
    "<ol>\n",
    "    <li>https://www.tensorflow.org/versions/r1.15/api_docs/python/tf</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Используемая литература \n",
    "\n",
    "Для подготовки данного методического пособия были использованы следующие ресурсы:\n",
    "<ol>\n",
    "    <li>https://www.tensorflow.org/</li>\n",
    "    <li>Шакла Н. — Машинное обучение и TensorFlow 2019</li>\n",
    "    <li>Википедия</li>\n",
    "    \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

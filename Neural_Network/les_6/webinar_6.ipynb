{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e28be6c-807a-4690-8479-a87c5481d0c4",
   "metadata": {},
   "source": [
    "# Вебинар 6. Сегментация   \n",
    "\n",
    "* Домашнее задание:  \n",
    "1.\tПопробуйте запустить с методички. ИЛИ\n",
    "2.\tДоделать код начатый на уроке. Можно пользоваться готовыми натренированными нейронками.\n",
    "\n",
    "Сдавать как обычно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4c8314-2828-4e4d-8a5b-fbe993c512f3",
   "metadata": {},
   "source": [
    "## Вставляем часть кода из методички по лабораторной работе №4\n",
    "лабораторная работа № 4 - [ссылка GeekBrains](https://view.officeapps.live.com/op/view.aspx?src=https%3A%2F%2Fgbcdn.mrgcdn.ru%2Fuploads%2Fasset%2F5874610%2Fattachment%2F92eb4ba1ca47bd7eefb6f549d5992e7e.docx&wdOrigin=BROWSELINK)  \n",
    "\n",
    "и загружаем данные для train и test:  \n",
    "train - [ссылка GeekBrains](https://gbcdn.mrgcdn.ru/uploads/asset/5874612/attachment/8adee08ef31aa26afce66d0dd8d3f126.zip)  \n",
    "test - [ссылка GeekBrains](https://gbcdn.mrgcdn.ru/uploads/asset/5874611/attachment/49824faeeeaa47bc07fa55b81334a613.zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e027346d-3d94-47a2-bf61-01c51bfe4bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Устанавливаем пакеты в окружение, если они не установлены\n",
    "\n",
    "# #библиотека для работы с изображениями в языке программирования Python\n",
    "# !pip install pillow \n",
    "\n",
    "# #библиотека языка Python, добавляющая поддержку больших многомерных массивов и матриц\n",
    "# !pip install numpy\n",
    "\n",
    "# #Python­-пакет с открытым кодом, который работает с массивами NumPy\n",
    "# !pip install scikit-image\n",
    "\n",
    "# #устанавливаем tensorflow для CPU\n",
    "# !pip install tensorflow\n",
    "\n",
    "# #устанавливаем keras\n",
    "# !pip install scikeras[tensorflow]\n",
    "\n",
    "# #отрисовка схем, графиков\n",
    "# !pip install graphviz\n",
    "# !pip install pydot\n",
    "\n",
    "# !pip install matpLotLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78dc6c83-302b-46cf-b3a2-1429b5927e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image   # библиотека для работы с изображениями в языке программирования Python\n",
    "import os\n",
    "import numpy as np      # библиотека языка Python, добавляющая поддержку больших многомерных массивов и матриц\n",
    "from skimage import io  # Python­-пакет с открытым кодом, который работает с массивами NumPy\n",
    "from keras.layers import Input, Conv2D, LeakyReLU, BatchNormalization, Concatenate, Conv2DTranspose, Dropout\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5fd4a57-b9bc-447a-8cc3-a1ec5b4a592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# задаём константы\n",
    "IMG_WIDTH = 640                       # Ширина итогового изображения\n",
    "IMG_LENGTH = 768                      # Длина итогового изображения\n",
    "IMG_SHAPE  = (IMG_WIDTH, IMG_LENGTH)  # Формат изображения (ширина, длина)\n",
    "CLASSES = 6                           # Число классов сегментирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd7bac7b-4cdc-4aec-94f2-3d6c6d1e528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(path):\n",
    "    \"\"\"\n",
    "    Функция загрузки изображений.\n",
    "\n",
    "    :param path: папка с изображениями; \n",
    "    :return: массив данных.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for path_image in sorted(os.listdir(path=path)):\n",
    "        image = Image.open(path + path_image)     # Открываем изображение.\n",
    "        image = tf.image.resize(image, IMG_SHAPE) # Изменяем размер изображения до IMG_SHAPE\n",
    "        data.append(np.array(image))              # Загружаем пиксели.\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1bbd054-ac81-4a71-9db1-10eb14beccee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем данные в массив\n",
    "X_train = download_data(\"train/images/\") # Исходные изображения из обучающей выборки данных\n",
    "Y_train = download_data(\"train/masks/\")  # Сегментированные исходные изображения из обучающей выборки\n",
    "X_test = download_data(\"test/images/\")   # Исходные изображения из тестовой выборки данных\n",
    "Y_test = download_data(\"test/masks/\")    # Сегментированные исходные изображения из тестовой выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81167d7-a119-4da6-a7ad-abd9f72a94f3",
   "metadata": {},
   "source": [
    "### Объявление функций предобработки и пост обработки данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5d8fd7a-5207-4b74-9487-c3a490fbff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Атрибут palette используется для установки цвета полос. Это помогает различать данные\n",
    "palette = {0 : (60, 16, 152),   # Building\n",
    "           1 : (132, 41, 246),  # Land\n",
    "           2 : (110, 193, 228), # Road\n",
    "           3 : (254, 221, 58),  # Vegetation\n",
    "           4 : (226, 169, 41),  # Water\n",
    "           5 : (155, 155, 155)} # Unlabeled\n",
    "\n",
    "# Переменная invert_palette позволяет проводить обратное преобразование, цвета в метку класса\n",
    "invert_palette = {v: k for k, v in palette.items()}\n",
    "\n",
    "# сегментация нейронной сети в RGB изображение\n",
    "def convert_to_color(arr_2d, palette=palette):\n",
    "    \"\"\" Numeric labels to RGB-color encoding \"\"\"\n",
    "    arr_3d = np.zeros((arr_2d.shape[0], arr_2d.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    for c, i in palette.items():\n",
    "        m = arr_2d == c\n",
    "        arr_3d[m] = i\n",
    "\n",
    "    return arr_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ceec10c-82c0-41a4-a914-25d8b8592ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Данная функция преобразует результат сегментации нейронной сети в RGB изображение, удобное для восприятия пользователя\n",
    "def convert_from_color(arr_3d, palette=invert_palette):\n",
    "    \"\"\" RGB-color encoding to grayscale labels \"\"\"\n",
    "    arr_2d = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.uint8)\n",
    "\n",
    "    arr_2d = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.int8)               # принадлежность каждого пикселя классу\n",
    "    min_distance = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.float32)+1000 # расстояние до ближайшего класса для пикселей\n",
    "    for c, i in palette.items():\n",
    "      distance = np.sum((arr_3d - np.array(c).reshape(1, 1, 3))**2, axis=-1)**(1/2)    # ищем расстояние для каждого пикселя до \n",
    "                                                                                       # проверяемого класса по евклиду рас-ие\n",
    "      condition = min_distance > distance             # поиск элементов меньше min_distance\n",
    "      min_distance[condition] = distance[condition]   # замена дистанции найденных элементов\n",
    "      arr_2d[condition] = i                           # замена класса найденных элементов\n",
    "\n",
    "    for c, i in palette.items():\n",
    "      m = np.all(arr_3d == np.array(c).reshape(1, 1, 3), axis=2)\n",
    "      arr_2d[m] = i\n",
    "\n",
    "    arr_2d = arr_2d.tolist()\n",
    "    for i in range(len(arr_2d)):\n",
    "      for j in range(len(arr_2d[0])):\n",
    "        label = [0, 0, 0, 0, 0, 0]\n",
    "        label[arr_2d[i][j]] = 1\n",
    "        arr_2d[i][j] = label\n",
    "    arr_2d = np.array(arr_2d)\n",
    "\n",
    "    return arr_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b9bb19-6c58-461c-b88c-b66310535a7a",
   "metadata": {},
   "source": [
    "### Предобработка исходных изображений и сегментированных изображений в ответ сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b0e9933-5ff8-44b7-b280-5c884f30180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Следующий блок кода подготавливает данные для использования нейронной сетью\n",
    "X_train_pred = np.array(X_train).reshape([7, IMG_WIDTH, IMG_LENGTH, 3])/255 \n",
    "X_test_pred = np.array(X_test).reshape([2, IMG_WIDTH, IMG_LENGTH, 3])/255   \n",
    "Y_train_pred = []\n",
    "for i in range(len(Y_train)):\n",
    "  Y_train_pred.append(convert_from_color(Y_train[i][:, :, :3]))\n",
    "Y_train_pred = np.array(Y_train_pred)\n",
    "Y_test_pred = []\n",
    "for i in range(len(Y_test)):\n",
    "  Y_test_pred.append(convert_from_color(Y_test[i][:, :, :3]))\n",
    "Y_test_pred = np.array(Y_test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53bddebf-a618-447b-814e-d732b93ad73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 640, 768, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3113e482-2b57-49b2-9dbf-3a8a7de19b1f",
   "metadata": {},
   "source": [
    "## Объявление топологии нейронной сети, компиляция и обучение\n",
    "Взял готовую топологию - [Ссылка GitHub](https://github.com/Mazepov/Cat_Segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b360d622-8e4d-4b6c-b44a-097bdae51995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(image_size, output_classes):\n",
    "\n",
    "    #Входной слой\n",
    "    input_layer = Input(shape=image_size + (3,))\n",
    "    conv_1 = Conv2D(64, 4, activation=LeakyReLU(),\n",
    "                                    strides=2, padding='same', kernel_initializer='glorot_normal',\n",
    "                                    use_bias=False)(input_layer)\n",
    "    #Сворачиваем\n",
    "    conv_1_1 = Conv2D(128, 4, activation=LeakyReLU(), strides=2,\n",
    "                                      padding='same', kernel_initializer='glorot_normal',\n",
    "                                      use_bias=False)(conv_1)\n",
    "    batch_norm_1 = BatchNormalization()(conv_1_1)\n",
    "\n",
    "    #2\n",
    "    conv_2 = Conv2D(256, 4, activation=LeakyReLU(), strides=2,\n",
    "                                      padding='same', kernel_initializer='glorot_normal',\n",
    "                                      use_bias=False)(batch_norm_1)\n",
    "    batch_norm_2 = BatchNormalization()(conv_2)\n",
    "\n",
    "    #3\n",
    "    conv_3 = Conv2D(512, 4, activation=LeakyReLU(), strides=2,\n",
    "                                      padding='same', kernel_initializer='glorot_normal',\n",
    "                                      use_bias=False)(batch_norm_2)\n",
    "    batch_norm_3 = BatchNormalization()(conv_3)\n",
    "\n",
    "    #4\n",
    "    conv_4 = Conv2D(512, 4, activation=LeakyReLU(), strides=2,\n",
    "                                      padding='same', kernel_initializer='glorot_normal',\n",
    "                                      use_bias=False)(batch_norm_3)\n",
    "    batch_norm_4 = BatchNormalization()(conv_4)\n",
    "\n",
    "    #5\n",
    "    conv_5 = Conv2D(512, 4, activation=LeakyReLU(), strides=2,\n",
    "                                      padding='same', kernel_initializer='glorot_normal',\n",
    "                                      use_bias=False)(batch_norm_4)\n",
    "    batch_norm_5 = BatchNormalization()(conv_5)\n",
    "\n",
    "    #6\n",
    "    conv_6 = Conv2D(512, 4, activation=LeakyReLU(), strides=2,\n",
    "                                      padding='same', kernel_initializer='glorot_normal',\n",
    "                                      use_bias=False)(batch_norm_5)\n",
    "\n",
    "\n",
    "    #Разворачиваем\n",
    "    #1\n",
    "    up_1 = Concatenate()([Conv2DTranspose(512, 4, activation='relu', strides=2,\n",
    "                                                                          padding='same',\n",
    "                                                                          kernel_initializer='glorot_normal',\n",
    "                                                                          use_bias=False)(conv_6), conv_5])\n",
    "    batch_up_1 = BatchNormalization()(up_1)\n",
    "\n",
    "    #Добавим Dropout от переобучения\n",
    "    batch_up_1 = Dropout(0.25)(batch_up_1)\n",
    "\n",
    "    #2\n",
    "    up_2 = Concatenate()([Conv2DTranspose(512, 4, activation='relu', strides=2,\n",
    "                                                                          padding='same',\n",
    "                                                                          kernel_initializer='glorot_normal',\n",
    "                                                                          use_bias=False)(batch_up_1), conv_4])\n",
    "    batch_up_2 = BatchNormalization()(up_2)\n",
    "    batch_up_2 = Dropout(0.25)(batch_up_2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #3\n",
    "    up_3 = Concatenate()([Conv2DTranspose(512, 4, activation='relu', strides=2,\n",
    "                                                                          padding='same',\n",
    "                                                                          kernel_initializer='glorot_normal',\n",
    "                                                                          use_bias=False)(batch_up_2), conv_3])\n",
    "    batch_up_3 = BatchNormalization()(up_3)\n",
    "    batch_up_3 = Dropout(0.25)(batch_up_3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #4\n",
    "    up_4 = Concatenate()([Conv2DTranspose(256, 4, activation='relu', strides=2,\n",
    "                                                                          padding='same',\n",
    "                                                                          kernel_initializer='glorot_normal',\n",
    "                                                                          use_bias=False)(batch_up_3), conv_2])\n",
    "    batch_up_4 = BatchNormalization()(up_4)\n",
    "\n",
    "\n",
    "    #5\n",
    "    up_5 = Concatenate()([Conv2DTranspose(128, 4, activation='relu', strides=2,\n",
    "                                                                          padding='same',\n",
    "                                                                          kernel_initializer='glorot_normal',\n",
    "                                                                          use_bias=False)(batch_up_4), conv_1_1])\n",
    "    batch_up_5 = BatchNormalization()(up_5)\n",
    "\n",
    "\n",
    "    #6\n",
    "    up_6 = Concatenate()([Conv2DTranspose(64, 4, activation='relu', strides=2,\n",
    "                                                                          padding='same',\n",
    "                                                                          kernel_initializer='glorot_normal',\n",
    "                                                                          use_bias=False)(batch_up_5), conv_1])\n",
    "    batch_up_6 = BatchNormalization()(up_6)\n",
    "\n",
    "\n",
    "    #Выходной слой\n",
    "    output_layer = Conv2DTranspose(output_classes, 4, activation='sigmoid', strides=2,\n",
    "                                                   padding='same',\n",
    "                                                   kernel_initializer='glorot_normal')(batch_up_6)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b8636d6-5c1f-447f-8635-32dafbd88d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet_model(image_size=IMG_SHAPE, output_classes=CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853db880-df3b-4962-8f78-d91351500cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "680245c1-0add-40f2-959e-847a2cdb17a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Компилируем модель\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1126ba-cd07-4190-99f7-411547c67800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем модель\n",
    "history = model.fit(X_train_pred, Y_train_pred, batch_size=1, epochs=10, validation_data=(X_test_pred, Y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5d30e1-345d-4e21-a93a-b118565c5237",
   "metadata": {},
   "source": [
    "### Отрисовка точности модели (при обучении и на тестовых данных)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3cccc4-cdaf-4dd0-8de6-596751cc7e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Точность модели')\n",
    "plt.ylabel('точность')\n",
    "plt.xlabel('количество эпох')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12865769-c041-43d4-8c61-ef5d0e4c8f93",
   "metadata": {},
   "source": [
    "### Выполняем predict для двух тестовых картинок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e44d821-d0c8-4cd1-9c92-492ad6f074d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Делаем сегментацию для двух тестовых картинок\n",
    "out = model.predict(X_test_pred[:2], batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65fe8bd-6784-4fbc-a8f2-fc880a8bb585",
   "metadata": {},
   "source": [
    "## Результат сегментации\n",
    "Отрисовка картинок - [Руководство по subplots в matplotlib](https://teletype.in/@pythontalk/matplotlib_subplot_tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef439a9-48a9-405c-ab20-2b23cbb50915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выведем 2-е тестовые картинки\n",
    "for i in range(2):\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.imshow(convert_to_color(np.argmax(Y_test_pred[i], axis=-1)))\n",
    "plt.suptitle('Желаемый результат сегментации', fontsize=19, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Выведем 2-е картинки полученые методом predict\n",
    "for i in range(2):\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.imshow(convert_to_color(np.argmax(out[i], axis=-1)))\n",
    "plt.suptitle('Полученный результат сегментации', fontsize=19, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5832400-4cbd-471b-8fed-f150dc6378fc",
   "metadata": {},
   "source": [
    "## Вывод:\n",
    "### Точность полученной модели более 80% при 100 эпохах, полученный результат сегментации очень похож на желаемый результат, но не идеален."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

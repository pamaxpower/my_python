{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import SimpleRNN, LSTM, GRU\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# построчное чтение из примера с текстом \n",
    "with open(\"alice_in_wonderland.txt\", 'rb') as _in:\n",
    "    lines = []\n",
    "    for line in _in:\n",
    "        # удаляем лишние пробелы, проводим к нижнему регистру, убираем все лишние символы\n",
    "        line = line.strip().lower().decode(\"ascii\", \"ignore\")\n",
    "        # удаляем пустые строки\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        lines.append(line)\n",
    "text = \" \".join(lines)\n",
    "# разбиваем текст на последовательность символов и пропускаем через множетсво, чтобы остались только уникальные символы\n",
    "chars = set([c for c in text])\n",
    "nb_chars = len(chars)\n",
    "nb_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "получаем 55 символов: 26 букв + знаки препинания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание индекса символов и reverse mapping чтобы передвигаться между значениями numerical\n",
    "# ID and a specific character. The numerical ID will correspond to a column\n",
    "# ID и определенный символ. Numerical ID будет соответсвовать колонке\n",
    "# число при использовании one-hot кодировки для представление входов символов\n",
    "char2index = {c: i for i, c in enumerate(chars)}    # индекс смвола\n",
    "index2char = {i: c for i, c in enumerate(chars)}    # символ индекса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для удобства выберете фиксированную длину последовательность 10 символов \n",
    "SEQLEN, STEP = 10, 1\n",
    "input_chars, label_chars = [], []\n",
    "\n",
    "# конвертация data в серии разных SEQLEN-length субпоследовательностей\n",
    "for i in range(0, len(text) - SEQLEN, STEP):\n",
    "    input_chars.append(text[i: i + SEQLEN])\n",
    "    label_chars.append(text[i + SEQLEN])\n",
    "\n",
    "# Вычисление one-hot encoding входных последовательностей X и следующего символа (the label) y\n",
    "\n",
    "X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=bool)\n",
    "y = np.zeros((len(input_chars), nb_chars), dtype=bool)\n",
    "for i, input_char in enumerate(input_chars):\n",
    "    for j, ch in enumerate(input_char):\n",
    "        X[i, j, char2index[ch]] = 1\n",
    "    y[i, char2index[label_chars[i]]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# установка ряда метапамертров  для нейронной сети и процесса тренировки\n",
    "BATCH_SIZE, HIDDEN_SIZE = 128, 128\n",
    "NUM_ITERATIONS = 15 # 25 должно быть достаточно\n",
    "NUM_EPOCHS_PER_ITERATION = 1\n",
    "NUM_PREDS_PER_EPOCH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Итерация #: 0\n",
      "1241/1241 [==============================] - 20s 14ms/step - loss: 2.3535\n",
      "Генерация из посева: ittle bat!\n",
      "ittle bat! the said the said the said the said the said the said the said the said the said the said the said ==================================================\n",
      "Итерация #: 1\n",
      "1241/1241 [==============================] - 17s 14ms/step - loss: 1.9787\n",
      "Генерация из посева: neezes: he\n",
      "neezes: her and the was she was she was she was she was she was she was she was she was she was she was she wa==================================================\n",
      "Итерация #: 2\n",
      "1241/1241 [==============================] - 17s 13ms/step - loss: 1.8158\n",
      "Генерация из посева: the cook. \n",
      "the cook. the the the the the the the the the the the the the the the the the the the the the the the the the ==================================================\n",
      "Итерация #: 3\n",
      "1241/1241 [==============================] - 17s 13ms/step - loss: 1.6993\n",
      "Генерация из посева:  that prov\n",
      " that proved the was the was the was the was the was the was the was the was the was the was the was the was t==================================================\n",
      "Итерация #: 4\n",
      "1241/1241 [==============================] - 17s 14ms/step - loss: 1.6117\n",
      "Генерация из посева: e doors al\n",
      "e doors all the mouse they well and they well and they well and they well and they well and they well and they==================================================\n",
      "Итерация #: 5\n",
      "1241/1241 [==============================] - 16s 13ms/step - loss: 1.5420\n",
      "Генерация из посева:  certainly\n",
      " certainly and the dormouse of the mouse the dormouse of the mouse the dormouse of the mouse the dormouse of t==================================================\n",
      "Итерация #: 6\n",
      "1241/1241 [==============================] - 16s 13ms/step - loss: 1.4843\n",
      "Генерация из посева: rnate form\n",
      "rnate format on the was a little thing i said the mock turtle as she was the was a little thing i said the moc==================================================\n",
      "Итерация #: 7\n",
      "1241/1241 [==============================] - 17s 13ms/step - loss: 1.4361\n",
      "Генерация из посева: rst was in\n",
      "rst was in the door and the dormouse to the door and the dormouse to the door and the dormouse to the door and==================================================\n",
      "Итерация #: 8\n",
      "1241/1241 [==============================] - 17s 14ms/step - loss: 1.3949\n",
      "Генерация из посева:  terms of \n",
      " terms of the thing she was the project gutenberg-tm electronic works in the states and she was the project gu==================================================\n",
      "Итерация #: 9\n",
      "1241/1241 [==============================] - 17s 13ms/step - loss: 1.3599\n",
      "Генерация из посева: ch a neck \n",
      "ch a neck to say in a little thing a little thing a little thing a little thing a little thing a little thing ==================================================\n",
      "Итерация #: 10\n",
      "1241/1241 [==============================] - 17s 13ms/step - loss: 1.3304\n",
      "Генерация из посева:  all perso\n",
      " all person the mouse of the singer of the thing it was soon and the beginning to herself to see it was soon a==================================================\n",
      "Итерация #: 11\n",
      "1241/1241 [==============================] - 17s 13ms/step - loss: 1.3036\n",
      "Генерация из посева: r this, an\n",
      "r this, and the project gutenberg-tm electronic work of the court and all the things and she was so the caterp==================================================\n",
      "Итерация #: 12\n",
      "1241/1241 [==============================] - 18s 14ms/step - loss: 1.2791\n",
      "Генерация из посева: son is, th\n",
      "son is, the mouse to herself to see it was a little sirter the project gutenberg-tm electronic work or and the==================================================\n",
      "Итерация #: 13\n",
      "1241/1241 [==============================] - 19s 15ms/step - loss: 1.2571\n",
      "Генерация из посева: he white r\n",
      "he white rabbit was the work and the thing as she was the work and the thing as she was the work and the thing==================================================\n",
      "Итерация #: 14\n",
      "1241/1241 [==============================] - 19s 15ms/step - loss: 1.2372\n",
      "Генерация из посева:  them at l\n",
      " them at last the project gutenberg-tm electronic works arching of the project gutenberg-tm electronic works a\n",
      "CPU times: total: 19min 37s\n",
      "Wall time: 6min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Создайте суперпростую рекуррентную нейронную сеть. Имеется один рекуррентный\n",
    "# слой, который производит вложение размера HIDDEN_SIZE из одноточечного\n",
    "# кодированного входного слоя. За ним следует плотный слой с полной связью\n",
    "# по набору возможных следующих символов, который преобразуется в\n",
    "# вероятностную оценку с помощью стандартной активации softmax с мультиклассовой\n",
    "# функцией потерь с перекрестной энтропией, связывающей предсказание с меткой одночасового\n",
    "# меткой символа кодировки.\n",
    "\n",
    "\n",
    "'''\n",
    "Создание очень простой рекуррентной нейронной сети. В ней будет один реккурентный закодированный входной слой. За ним последует полносвязный слой связанный с набором возможных следующих символов, которые конвертированы в вероятностные результаты через стандартную softmax активацию с multi-class cross-encoding loss функцию ссылающуются на предсказание one-hot encoding лейбл символа\n",
    "'''\n",
    "\n",
    "model = Sequential()\n",
    "model.add(\n",
    "    GRU(  # вы можете изменить эту часть на LSTM или SimpleRNN, чтобы попробовать альтернативы\n",
    "        HIDDEN_SIZE,\n",
    "        return_sequences=False,\n",
    "        input_shape=(SEQLEN, nb_chars),\n",
    "        unroll=True\n",
    "    )\n",
    ")\n",
    "model.add(Dense(nb_chars))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")\n",
    "\n",
    "\n",
    "# выполнение серий тренировочных и демонстрационных итераций \n",
    "for iteration in range(NUM_ITERATIONS):\n",
    "\n",
    "    # для каждой итерации запуск передачи данных в модель \n",
    "    print(\"=\" * 50)\n",
    "    print(\"Итерация #: %d\" % (iteration))\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
    "\n",
    "    # Select a random example input sequence.\n",
    "    test_idx = np.random.randint(len(input_chars))\n",
    "    test_chars = input_chars[test_idx]\n",
    "\n",
    "    # для числа шагов предсказаний использование текущей тренируемой модели \n",
    "    # конструирование one-hot encoding для тестирования input и добавление предсказания.\n",
    "    print(\"Генерация из посева: %s\" % (test_chars))\n",
    "    print(test_chars, end=\"\")\n",
    "    \n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "\n",
    "        # здесь one-hot encoding.\n",
    "        X_test = np.zeros((1, SEQLEN, nb_chars))\n",
    "        for j, ch in enumerate(test_chars):\n",
    "            X_test[0, j, char2index[ch]] = 1\n",
    "\n",
    "        # осуществление предсказания с помощью текущей модели.\n",
    "        pred = model.predict(X_test, verbose=0)[0]\n",
    "        y_pred = index2char[np.argmax(pred)]\n",
    "\n",
    "        # вывод предсказания добавленного к тестовому примеру \n",
    "        print(y_pred, end=\"\")\n",
    "\n",
    "        # инкрементация тестового примера содержащего предсказание\n",
    "        test_chars = test_chars[1:] + y_pred\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1:35:35 дописать двунаправленную сеть"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

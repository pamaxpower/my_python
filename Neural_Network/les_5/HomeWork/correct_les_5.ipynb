{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подгружаем модуль re для работы с текстом\n",
    "import re\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Слова\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../train_data.txt', 'r', encoding='utf-8') as f:\n",
    "    texts = f.read()\n",
    "    # убираем первый невидимый символ\n",
    "    texts = texts.replace('\\ufeff', '') \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# набор уникальных слов\n",
    "maxWordsCount = 1000\n",
    "tokenizer = Tokenizer(num_words=maxWordsCount, \n",
    "                      filters='!–\"—#$%&amp;()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r«»',\n",
    "                      lower=True,\n",
    "                      split=' ',\n",
    "                      char_level=False)\n",
    "tokenizer.fit_on_texts([texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('вы', 3), ('лучший', 1), ('ответ', 1), ('на', 1), ('проблемы', 1), ('которые', 1), ('возникли', 1), ('в', 3), ('понедельник', 2), ('думайте', 1)]\n"
     ]
    }
   ],
   "source": [
    "dist = list(tokenizer.word_counts.items())\n",
    "print(dist[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразуем текст в последовательность чисел в соответсвии со словарем\n",
    "data = tokenizer.texts_to_sequences([texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  2,\n",
       "  3,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  2,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  1,\n",
       "  20,\n",
       "  2,\n",
       "  3,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  1,\n",
       "  25,\n",
       "  26]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n",
    "# в текст вместо каждого слова поставили цифру из токенайзера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 1000)\n"
     ]
    }
   ],
   "source": [
    "# категоризируем слова в вектор\n",
    "res = keras.utils.to_categorical(data[0], num_classes=maxWordsCount)\n",
    "print( res.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(31, 1000): 31 - кол-во слов в тексте, 1000 - длина вектора на каждое слово (можно было сделать меньше, напр, 50 или 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# число слов, на которых строится прогноз\n",
    "inp_words = 3\n",
    "n = res.shape[0]-inp_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([res[i:i+inp_words, :] for i in range(n)])\n",
    "Y = res[inp_words:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 128)               144512    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              129000    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 273,512\n",
      "Trainable params: 273,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Input((inp_words, maxWordsCount)),\n",
    "    SimpleRNN(128, activation='tanh'),\n",
    "    Dense(maxWordsCount, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'],\n",
    "              optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Настраиваем защиту от переобучения\n",
    "estop = EarlyStopping(monitor='accuracy', patience=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 14s 14s/step - loss: 6.9170 - accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 6.8915 - accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.8659 - accuracy: 0.0357\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.8400 - accuracy: 0.1786\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.8136 - accuracy: 0.2500\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.7865 - accuracy: 0.5000\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.7583 - accuracy: 0.8571\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.7287 - accuracy: 0.9286\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6.6975 - accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 6.6642 - accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.6284 - accuracy: 1.0000\n",
      "Обучение остановлено на 10 эпохе\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, batch_size=32, epochs=50, callbacks=estop)\n",
    "if estop.stopped_epoch >= 1:\n",
    "    print(f'Обучение остановлено на {estop.stopped_epoch} эпохе')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildPhrase(texts, str_len = 20):\n",
    "  res = texts\n",
    "  data = tokenizer.texts_to_sequences([texts])[0]\n",
    "\n",
    "  for i in range(str_len):\n",
    "    x = keras.utils.to_categorical(data[i: i+inp_words], num_classes=maxWordsCount) # преобразуем в One-Hot-encoding\n",
    "    inp = x.reshape(1, inp_words, maxWordsCount)\n",
    "    pred = model.predict( inp ) # предсказываем OHE четвертого символа\n",
    "    indx = pred.argmax(axis=1)[0]\n",
    "    data.append(indx)\n",
    " \n",
    "    res += \" \" + tokenizer.index_word[indx] # дописываем строку\n",
    " \n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 0 into shape (1,3,1000)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mbuildPhrase\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mпозитив добавляет годы\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(res)\n",
      "Cell \u001b[1;32mIn[15], line 7\u001b[0m, in \u001b[0;36mbuildPhrase\u001b[1;34m(texts, str_len)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(str_len):\n\u001b[0;32m      6\u001b[0m   x \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mto_categorical(data[i: i\u001b[38;5;241m+\u001b[39minp_words], num_classes\u001b[38;5;241m=\u001b[39mmaxWordsCount) \u001b[38;5;66;03m# преобразуем в One-Hot-encoding\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m   inp \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minp_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxWordsCount\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m   pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict( inp ) \u001b[38;5;66;03m# предсказываем OHE четвертого символа\u001b[39;00m\n\u001b[0;32m      9\u001b[0m   indx \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 0 into shape (1,3,1000)"
     ]
    }
   ],
   "source": [
    "res = buildPhrase(\"позитив добавляет годы\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ошибка на семинаре была в том, что мы использовать аргументом для функции строчку, которой не было файле train_data.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поменяв текст на \"Думайте позитивно и\" и мы получим вполне ожидаемый результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "Думайте позитивно и верьте в свою способность достигать отличных результатов если вы смогли в понедельник подняться с постели значит вы супер герой смогли\n"
     ]
    }
   ],
   "source": [
    "res = buildPhrase(\"Думайте позитивно и\")\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

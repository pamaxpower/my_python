Виды задач:
1) Классификация - когда известно количество вариантов на выходе (дискретная величина) - определение мальчик/девочка
2) Регрессия - на выходе непрерывная величина (множество возможных значений) - предсказание цен на недвижимость или автомобиль





Переобучение - это поведение модели, когда на обучающих данных она показывает хорошие результаты, а на тестовых - плохие. Это объясняется тем, что модель просто запоминает ответы обучающих данных.

Как бороться с переобучением:
* регуляризация - проще говоря "наказывание" модели за неправильный ответ, ограничивание в подборе весов
* кросс-валидация - разбивание датасета на несколько частей (батчей) и попеременное использование данных для обучения и теста (например, разбили на 5 частей: 1,3,4 взяли для обучения, 2,5 - для теста, затем поменяли батчи и 2,3,5 взяли для обучения, 1,4 - для теста и тд)

Эпоха - проход всего датасета через вся нейронную сеть от начала до конца
Иттерация - количество прогонов всех батчей для завершения эпохи (размер датасета / кол-во батчей)
Batch_size - часть дата сета (делят, чтоб избежать перегрузки оперативной памяти)

Размер батча влияет на процесс обучения:
* если слишком маленький - появляется стохастическая случайность; застревание в локальных минимумах; обучение проходит быстрее, но нужно много итераций
* если большой - эффективен для параллельной обработки данных; обновленние модели проходит медленнее; процесс обучения более стабильный, но занимает много времени

Функция потерь - математический процесс, который количественно определяет погрешность между прогнозом модели и фактическим целевым значением

![Виды функции потерь](/les_2/images/image-4.png)

![Чувствительность к выбросам](/les_2/images/image-5.png)
Выброс - высокое или низкое аномальное значение

Подбор оптимального количества нейронов:
* количество нейронов в скрытом слое можно выбрать равным среднему от количества входных нейронов и выходных нейронов
* каждый раз (слой за слоем) уменьшаем количество нейронов (от входных до выходных): 
    - уменьшаем плотность нейронов и кол-во параметров, 
    - иерархическое изменение признаков (изменение в более абстрактные)
    - постепенное уменьшение нейронов предотвращает переобучение модели

![Матрица ошибок](/les_2/images/image.png)
![Расшифровка метрик](/les_2/images/image-1.png)
* accuracy - точность модели (доля true-правильных ответов от всех возможных ответов)
* precision - доля объектов, названных моделью ПОЛОЖИТЕЛЬНЫМИ и на самом деле являющиеся ПОЛОЖИТЕЛЬНЫМИ
* recall - полнота - какую долю объектов положительного класса из всех объектов положительного класса нашел алгоритм (какая часть предсказаний на самом деле оказалась верной)
* f1 - 

Матрица ошибок в sklearn: 
print(classification_report(y_test_bin, y(pred)))


AUC ROC показывает насколько модель правильно классифицирует экземпляры
![AUC ROC](/les_2/images/image-2.png)
![AUC ROC модели в lesson_2](/les_2/images/image-3.png)

Оптимизаторы в обучении
![Градиентный спуск](/les_2/images/image-6.png) - самый популярный
![SGD](/les_2/images/image-7.png) - стохастический
![Adam](/les_2/images/image-8.png)